2025-06-06:09:12:32 INFO     [__main__:440] Selected Tasks: ['wikitext']
2025-06-06:09:12:32 INFO     [evaluator:185] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-06-06:09:12:32 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/mnt/lustre/work/geiger/gwb345/models/llama-3.1-8b-hf', 'device_map': 'auto'}
2025-06-06:09:12:32 WARNING  [accelerate.utils.other:441] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-06-06:09:12:32 INFO     [models.huggingface:137] Using device 'cuda'
2025-06-06:09:12:32 INFO     [models.huggingface:388] Model parallel was set to False.
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 79.47it/s]
2025-06-06:09:12:40 WARNING  [api.task:844] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2025-06-06:09:12:40 WARNING  [api.task:856] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2025-06-06:09:12:40 WARNING  [api.task:844] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2025-06-06:09:12:40 WARNING  [api.task:856] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2025-06-06:09:12:40 WARNING  [api.task:844] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2025-06-06:09:12:40 WARNING  [api.task:856] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
2025-06-06:09:12:43 INFO     [api.task:434] Building contexts for wikitext on rank 0...
100%|██████████| 62/62 [00:00<00:00, 722.66it/s]
2025-06-06:09:12:43 INFO     [evaluator:555] Running loglikelihood_rolling requests
Passed argument batch_size = auto. Detecting largest batch size
Determined Largest batch size: 1
100%|██████████| 62/62 [00:00<00:00, 98.80it/s] 
Running loglikelihood requests: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00, 17.56it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00, 26.64it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]
Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]
2025-06-06:09:13:39 INFO     [loggers.evaluation_tracker:209] Saving results aggregated
hf (pretrained=/mnt/lustre/work/geiger/gwb345/models/llama-3.1-8b-hf,device_map=auto), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto
| Tasks  |Version|Filter|n-shot|    Metric     |   |Value |   |Stderr|
|--------|------:|------|-----:|---------------|---|-----:|---|------|
|wikitext|      2|none  |     0|bits_per_byte  |↓  |0.5374|±  |   N/A|
|        |       |none  |     0|byte_perplexity|↓  |1.4513|±  |   N/A|
|        |       |none  |     0|word_perplexity|↓  |7.3293|±  |   N/A|
